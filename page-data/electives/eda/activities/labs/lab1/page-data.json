{"componentChunkName":"component---src-pages-electives-eda-activities-labs-lab-1-index-mdx","path":"/electives/eda/activities/labs/lab1/","result":{"pageContext":{"frontmatter":{"title":"Event-Driven Architecture Lab 1 - Getting Started with Producing & Consuming","description":"Lab activities associated with producing and consuming messages from an IBM Event Streams on Cloud instance, to be used with event-driven architecture enablement."},"relativePagePath":"/electives/eda/activities/labs/lab1/index.mdx","titleType":"page","MdxNode":{"id":"d6713080-12cf-5e83-a996-6d2cf176ba63","children":[],"parent":"deb40c78-7184-5d87-aff1-94ebb0b6ee33","internal":{"content":"---\ntitle: Event-Driven Architecture Lab 1 - Getting Started with Producing & Consuming\ndescription: Lab activities associated with producing and consuming messages from an IBM Event Streams on Cloud instance, to be used with event-driven architecture enablement.\n---\n\n## Problem\n\nProduce and consume events to and from an IBM Event Streams on Cloud instance, using NodeJS and Java console samples on your local workstation.\n\n### Using the NodeJS sample\n\nTo complete this lab scenario, you will need to perform the following steps:\n\n- Make use of the NodeJS project located at https://github.com/ibm-messaging/event-streams-samples/tree/master/kafka-nodejs-console-sample\n- Acquire the necessary connection information to your IBM Event Streams on Cloud instance\n- Build the Docker image\n  - _**NOTE:**_ If the Docker image fails to build, you may need to update the Dockerfile to use a specific, non-latest base image from Ubuntu. This is due to underlying packaging changes between Ubuntu versions.\n  - Change `FROM ubuntu` to `FROM ubuntu:18.04` in the [Dockerfile](https://github.com/ibm-messaging/event-streams-samples/blob/master/kafka-nodejs-console-sample/Dockerfile) and the image build should complete successfully.\n- Run the Docker image, while passing in the IBM Event Streams on Cloud boostrap server and API key information as command-line parameters\n\n### Use the Java sample\n\n- Make use of the Java project located at https://github.com/ibm-messaging/event-streams-samples/tree/master/kafka-java-console-sample\n- Acquire the necessary connection information to your IBM Event Streams on Cloud instance\n- Build the Docker image\n- Run the Docker image, while passing in the IBM Event Streams on Cloud boostrap server and API key information as command-line parameters\n\n## Verification\n\nWhen you have completed this lab, you will see output similar to the following in your terminal window. The topic name will be specific to the implementation technology that you are using for the given sample.\n\n__NodeJS__\n```\nCreating the topic kafka-nodejs-console-sample-topic with AdminClient\nAdminClient connected\nThis sample app will run until interrupted.\nThe consumer has connected.\nThe producer has connected.\nNo messages consumed\nMessage produced, partition: 0 offset: 535\nMessage produced, partition: 0 offset: 536\nNo messages consumed\nMessage produced, partition: 0 offset: 537\nMessage consumed: topic=kafka-nodejs-console-sample-topic, partition=0, offset=535, key=Key0, value=This is a test message #0\nMessage consumed: topic=kafka-nodejs-console-sample-topic, partition=0, offset=536, key=Key1, value=This is a test message #1\nMessage consumed: topic=kafka-nodejs-console-sample-topic, partition=0, offset=537, key=Key2, value=This is a test message #2\nMessage produced, partition: 0 offset: 538\nMessage consumed: topic=kafka-nodejs-console-sample-topic, partition=0, offset=538, key=Key3, value=This is a test message #3\n```\n\n__Java__\n```\n[2020-04-28 20:44:53,004] INFO Using command line arguments to find credentials. (com.eventstreams.samples.EventStreamsConsoleSample)\n[2020-04-28 20:44:53,005] INFO Kafka Endpoints: broker...cloud.ibm.com:9093 (com.eventstreams.samples.EventStreamsConsoleSample)\n[2020-04-28 20:44:56,639] INFO Creating the topic kafka-java-console-sample-topic (com.eventstreams.samples.EventStreamsConsoleSample)\n[2020-04-28 20:44:59,826] INFO Topic kafka-java-console-sample-topic already exists (com.eventstreams.samples.EventStreamsConsoleSample)\n[2020-04-28 20:45:00,816] INFO [Partition(topic = kafka-java-console-sample-topic, partition = 0, leader = 3, replicas = [3,1,2], isr = [3,2,1], offlineReplicas = [])] (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:00,817] INFO class com.eventstreams.samples.ConsumerRunnable is starting. (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:01,646] INFO [Partition(topic = kafka-java-console-sample-topic, partition = 0, leader = 3, replicas = [3,1,2], isr = [3,2,1], offlineReplicas = [])] (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:01,646] INFO EventStreamsConsoleSample will run until interrupted. (com.eventstreams.samples.EventStreamsConsoleSample)\n[2020-04-28 20:45:01,646] INFO class com.eventstreams.samples.ProducerRunnable is starting. (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:02,590] INFO Message produced, offset: 195 (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:03,819] INFO No messages consumed (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:04,697] INFO Message produced, offset: 196 (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:06,795] INFO Message produced, offset: 197 (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:06,821] INFO No messages consumed (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:07,020] INFO Message consumed: ConsumerRecord(topic = kafka-java-console-sample-topic, partition = 0, leaderEpoch = 56, offset = 197, CreateTime = 1588106706698, serialized key size = 3, serialized value size = 25, headers = RecordHeaders(headers = [], isReadOnly = false), key = key, value = This is a test message #2) (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:08,933] INFO Message produced, offset: 198 (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:08,954] INFO Message consumed: ConsumerRecord(topic = kafka-java-console-sample-topic, partition = 0, leaderEpoch = 56, offset = 198, CreateTime = 1588106708797, serialized key size = 3, serialized value size = 25, headers = RecordHeaders(headers = [], isReadOnly = false), key = key, value = This is a test message #3) (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:11,024] INFO Message consumed: ConsumerRecord(topic = kafka-java-console-sample-topic, partition = 0, leaderEpoch = 56, offset = 199, CreateTime = 1588106710933, serialized key size = 3, serialized value size = 25, headers = RecordHeaders(headers = [], isReadOnly = false), key = key, value = This is a test message #4) (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:11,028] INFO Message produced, offset: 199 (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:13,114] INFO Message produced, offset: 200 (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:13,115] INFO Message consumed: ConsumerRecord(topic = kafka-java-console-sample-topic, partition = 0, leaderEpoch = 56, offset = 200, CreateTime = 1588106713028, serialized key size = 3, serialized value size = 25, headers = RecordHeaders(headers = [], isReadOnly = false), key = key, value = This is a test message #5) (com.eventstreams.samples.ConsumerRunnable)\n```\n\n## Extra credit\n\nUsing your knowledge of containerization and CI/CD pipelines gained through the bootcamp, construct a pipeline that will build, deploy, and manage these sample applications on a Kubernetes or OpenShift cluster on IBM Cloud.\n\n## References\n\n- [IBM Event Streams on IBM Cloud - Getting started tutorial](https://cloud.ibm.com/docs/EventStreams?topic=eventstreams-getting_started)\n","type":"Mdx","contentDigest":"67b279acb18df262fc84431b78e4e27c","owner":"gatsby-plugin-mdx","counter":576},"frontmatter":{"title":"Event-Driven Architecture Lab 1 - Getting Started with Producing & Consuming","description":"Lab activities associated with producing and consuming messages from an IBM Event Streams on Cloud instance, to be used with event-driven architecture enablement."},"exports":{},"rawBody":"---\ntitle: Event-Driven Architecture Lab 1 - Getting Started with Producing & Consuming\ndescription: Lab activities associated with producing and consuming messages from an IBM Event Streams on Cloud instance, to be used with event-driven architecture enablement.\n---\n\n## Problem\n\nProduce and consume events to and from an IBM Event Streams on Cloud instance, using NodeJS and Java console samples on your local workstation.\n\n### Using the NodeJS sample\n\nTo complete this lab scenario, you will need to perform the following steps:\n\n- Make use of the NodeJS project located at https://github.com/ibm-messaging/event-streams-samples/tree/master/kafka-nodejs-console-sample\n- Acquire the necessary connection information to your IBM Event Streams on Cloud instance\n- Build the Docker image\n  - _**NOTE:**_ If the Docker image fails to build, you may need to update the Dockerfile to use a specific, non-latest base image from Ubuntu. This is due to underlying packaging changes between Ubuntu versions.\n  - Change `FROM ubuntu` to `FROM ubuntu:18.04` in the [Dockerfile](https://github.com/ibm-messaging/event-streams-samples/blob/master/kafka-nodejs-console-sample/Dockerfile) and the image build should complete successfully.\n- Run the Docker image, while passing in the IBM Event Streams on Cloud boostrap server and API key information as command-line parameters\n\n### Use the Java sample\n\n- Make use of the Java project located at https://github.com/ibm-messaging/event-streams-samples/tree/master/kafka-java-console-sample\n- Acquire the necessary connection information to your IBM Event Streams on Cloud instance\n- Build the Docker image\n- Run the Docker image, while passing in the IBM Event Streams on Cloud boostrap server and API key information as command-line parameters\n\n## Verification\n\nWhen you have completed this lab, you will see output similar to the following in your terminal window. The topic name will be specific to the implementation technology that you are using for the given sample.\n\n__NodeJS__\n```\nCreating the topic kafka-nodejs-console-sample-topic with AdminClient\nAdminClient connected\nThis sample app will run until interrupted.\nThe consumer has connected.\nThe producer has connected.\nNo messages consumed\nMessage produced, partition: 0 offset: 535\nMessage produced, partition: 0 offset: 536\nNo messages consumed\nMessage produced, partition: 0 offset: 537\nMessage consumed: topic=kafka-nodejs-console-sample-topic, partition=0, offset=535, key=Key0, value=This is a test message #0\nMessage consumed: topic=kafka-nodejs-console-sample-topic, partition=0, offset=536, key=Key1, value=This is a test message #1\nMessage consumed: topic=kafka-nodejs-console-sample-topic, partition=0, offset=537, key=Key2, value=This is a test message #2\nMessage produced, partition: 0 offset: 538\nMessage consumed: topic=kafka-nodejs-console-sample-topic, partition=0, offset=538, key=Key3, value=This is a test message #3\n```\n\n__Java__\n```\n[2020-04-28 20:44:53,004] INFO Using command line arguments to find credentials. (com.eventstreams.samples.EventStreamsConsoleSample)\n[2020-04-28 20:44:53,005] INFO Kafka Endpoints: broker...cloud.ibm.com:9093 (com.eventstreams.samples.EventStreamsConsoleSample)\n[2020-04-28 20:44:56,639] INFO Creating the topic kafka-java-console-sample-topic (com.eventstreams.samples.EventStreamsConsoleSample)\n[2020-04-28 20:44:59,826] INFO Topic kafka-java-console-sample-topic already exists (com.eventstreams.samples.EventStreamsConsoleSample)\n[2020-04-28 20:45:00,816] INFO [Partition(topic = kafka-java-console-sample-topic, partition = 0, leader = 3, replicas = [3,1,2], isr = [3,2,1], offlineReplicas = [])] (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:00,817] INFO class com.eventstreams.samples.ConsumerRunnable is starting. (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:01,646] INFO [Partition(topic = kafka-java-console-sample-topic, partition = 0, leader = 3, replicas = [3,1,2], isr = [3,2,1], offlineReplicas = [])] (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:01,646] INFO EventStreamsConsoleSample will run until interrupted. (com.eventstreams.samples.EventStreamsConsoleSample)\n[2020-04-28 20:45:01,646] INFO class com.eventstreams.samples.ProducerRunnable is starting. (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:02,590] INFO Message produced, offset: 195 (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:03,819] INFO No messages consumed (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:04,697] INFO Message produced, offset: 196 (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:06,795] INFO Message produced, offset: 197 (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:06,821] INFO No messages consumed (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:07,020] INFO Message consumed: ConsumerRecord(topic = kafka-java-console-sample-topic, partition = 0, leaderEpoch = 56, offset = 197, CreateTime = 1588106706698, serialized key size = 3, serialized value size = 25, headers = RecordHeaders(headers = [], isReadOnly = false), key = key, value = This is a test message #2) (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:08,933] INFO Message produced, offset: 198 (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:08,954] INFO Message consumed: ConsumerRecord(topic = kafka-java-console-sample-topic, partition = 0, leaderEpoch = 56, offset = 198, CreateTime = 1588106708797, serialized key size = 3, serialized value size = 25, headers = RecordHeaders(headers = [], isReadOnly = false), key = key, value = This is a test message #3) (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:11,024] INFO Message consumed: ConsumerRecord(topic = kafka-java-console-sample-topic, partition = 0, leaderEpoch = 56, offset = 199, CreateTime = 1588106710933, serialized key size = 3, serialized value size = 25, headers = RecordHeaders(headers = [], isReadOnly = false), key = key, value = This is a test message #4) (com.eventstreams.samples.ConsumerRunnable)\n[2020-04-28 20:45:11,028] INFO Message produced, offset: 199 (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:13,114] INFO Message produced, offset: 200 (com.eventstreams.samples.ProducerRunnable)\n[2020-04-28 20:45:13,115] INFO Message consumed: ConsumerRecord(topic = kafka-java-console-sample-topic, partition = 0, leaderEpoch = 56, offset = 200, CreateTime = 1588106713028, serialized key size = 3, serialized value size = 25, headers = RecordHeaders(headers = [], isReadOnly = false), key = key, value = This is a test message #5) (com.eventstreams.samples.ConsumerRunnable)\n```\n\n## Extra credit\n\nUsing your knowledge of containerization and CI/CD pipelines gained through the bootcamp, construct a pipeline that will build, deploy, and manage these sample applications on a Kubernetes or OpenShift cluster on IBM Cloud.\n\n## References\n\n- [IBM Event Streams on IBM Cloud - Getting started tutorial](https://cloud.ibm.com/docs/EventStreams?topic=eventstreams-getting_started)\n","fileAbsolutePath":"/home/runner/work/learning-cloudnative-101/learning-cloudnative-101/src/pages/electives/eda/activities/labs/lab1/index.mdx"}}},"staticQueryHashes":["1364590287","137577622","137577622","2102389209","2102389209","2456312558","2746626797","2746626797","3037994772","3037994772","530240012","530240012","768070550"]}